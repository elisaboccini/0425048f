{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "mount_file_id": "1Mj5eWvCgSjtiPYat4dYUdeVc3N2LLIFO",
      "authorship_tag": "ABX9TyN5vkor6hvLQQkmQOu/W5DY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elisaboccini/0425048f/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHh0a2VlZc6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "'''Entropy'''\n",
        "def scaled_entropy(y):\n",
        "    counts = np.bincount(y)\n",
        "    probs = counts / len(y)\n",
        "    return -np.sum([p * np.log2(p) for p in probs if p > 0]) #since log is not defined for negative numbers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Node: \n",
        "    def __init__(self, feature = None, threshold = None, left = None, right = None,*, value = None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.value = value    \n",
        "    \n",
        "    \n",
        "    def is_leaf_node(self):\n",
        "        return self.value is not None\n",
        "    \n",
        "class DecisionTree:\n",
        "    def __init__(self, min_samples_split=2, max_depth= 10, n_feats=25):\n",
        "        self.min_samples_split= min_samples_split\n",
        "        self.max_depth= max_depth\n",
        "        self.n_feats= n_feats\n",
        "        self.root= None\n",
        "        \n",
        "    def fit(self,X,y):\n",
        "        #grow tree\n",
        "        self.n_feats= X.shape[1] if not self.n_feats else min(self.n_feats, X.shape[1]) #if not specified n of features for the split take the n of rows in X, otherwise the mmin among the nfeats specified above and the n of rows of X\n",
        "        self.root = self._grow_tree(X,y)\n",
        "        \n",
        "    def _grow_tree(self, X, y , depth = 0):\n",
        "        n_samples, n_features = X.shape\n",
        "        n_labels = len(np.unique(y))\n",
        "        \n",
        "        #stopping criteria\n",
        "        if (depth >= self.max_depth\n",
        "            or n_labels ==1\n",
        "            or n_samples < self.min_samples_split):\n",
        "            leaf_value = self.most_common_label(y)\n",
        "            return Node(value= leaf_value)  #so if it meets stoppingcrit. ok, otherwise it continues\n",
        "        \n",
        "        feat_idxs = np.random.choice(n_features, self.n_feats, replace= False) #it selectes indexes from the n of features randomly without replacement since we don't want same index many times and the array has lenght= self.n_feats\n",
        "        \n",
        "        #greedy search\n",
        "        best_feat, best_threshold = self.bestsplit_criteria(X, y, feat_idxs)\n",
        "        left_idxs, right_idxs = self._split(X[:, best_feat], best_threshold)\n",
        "        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth+1) #iterate and grow the tree at the left of the node\n",
        "        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth+1) #iterate and grow the tree at the right of the node\n",
        "        return Node(best_feat, best_threshold, left, right)\n",
        "    \n",
        "   \n",
        "                                            \n",
        "    def bestsplit_criteria(self, X, y, feat_idxs):\n",
        "        best_gain = -1\n",
        "        split_idx, split_threshold = None, None\n",
        "        for feat_idx in feat_idxs:\n",
        "            X_column= X[:, feat_idx]\n",
        "            thresholds = np.unique(X_column)\n",
        "            for threshold in thresholds:\n",
        "                gain = self._information_gain(y, X_column, threshold)\n",
        "                \n",
        "                if gain > best_gain:\n",
        "                    best_gain= gain\n",
        "                    split_idx = feat_idx\n",
        "                    split_threshold = threshold\n",
        "        return split_idx, split_threshold\n",
        "    \n",
        "    def _split(self, X_column, split_threshold):\n",
        "        left_idxs = np.argwhere(X_column <= split_threshold).flatten()\n",
        "        right_idxs = np.argwhere(X_column > split_threshold).flatten()\n",
        "        return left_idxs, right_idxs\n",
        "            \n",
        "    \n",
        "    \n",
        "    \n",
        "    def _information_gain(self, y, X_column, split_threshold):\n",
        "        parent_entropy = scaled_entropy(y)\n",
        "        #generate split\n",
        "        left_idxs = np.argwhere(X_column <= split_threshold).flatten()\n",
        "        right_idxs = np.argwhere(X_column > split_threshold).flatten()\n",
        "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
        "            return 0 #as information gain\n",
        "        n_left, n_right = len(left_idxs), len(right_idxs)\n",
        "        e_left, e_right = scaled_entropy(y[left_idxs]), scaled_entropy(y[right_idxs])\n",
        "        #weighted avg of children' entropy\n",
        "        child_entropy = (n_left/len(y))*e_left + (n_right/len(y))*e_right                                          \n",
        "        #return information gain\n",
        "        info_gain = parent_entropy- child_entropy\n",
        "        return info_gain            \n",
        "\n",
        "\n",
        "    \n",
        "        \n",
        "    #predict tree\n",
        "    def predict(self, X):\n",
        "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
        "    \n",
        "    def _traverse_tree(self, x, node):\n",
        "        if node.is_leaf_node():\n",
        "            return node.value\n",
        "        \n",
        "        if x[node.feature] <= node.threshold:\n",
        "            return self._traverse_tree(x,node.left)\n",
        "        return self._traverse_tree(x, node.right)\n",
        "         \n",
        "        \n",
        "    def most_common_label(self,y):\n",
        "        most_common = Counter(y).most_common(1)[0][0] #since most_common is a list of tuples we look for the first element of the first tuple\n",
        "        return most_common\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruMW-oIqasjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Implementation on the dataset'''\n",
        "import pandas as pd\n",
        "df_train = pd.read_csv('drive/My Drive/fashion_mnist_data/fashion-mnist_train.csv')     \n",
        "df_test = pd.read_csv('drive/My Drive/fashion_mnist_data/fashion-mnist_test.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pKaTHtqbC76",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c47ce723-498d-4dec-cef4-302a8accf7e5"
      },
      "source": [
        "df_train.isnull()\n",
        "df_train.isnull().sum().sum()\n",
        "\n",
        "train_X = df_train.drop(\"label\",1).values \n",
        "train_y = df_train['label'].values #all the rows of column -1\n",
        "print(train_y)\n",
        "\n",
        "scaled_entropy(train_y)  #we can not put target in this beacuse the first line seeks\n",
        "#for the column label \n",
        "\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 9 6 ... 8 8 7]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.321928094887362"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyI483MwbEO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tree = DecisionTree()\n",
        "tree.fit(train_X, train_y)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvyILVSqbLIc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "16df93a8-2086-44cb-f94c-3baf61b0384f"
      },
      "source": [
        "#Predictions on the test set\n",
        "df_test.isnull()\n",
        "df_test.isnull().sum().sum()\n",
        "\n",
        "test_X = df_test.drop(\"label\",1).values\n",
        "test_y = df_test['label'].values\n",
        "\n",
        "results = tree.predict(test_X)\n",
        "print(results)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def accuracy(real, predicted):\n",
        "\tcorrect = 0\n",
        "\tfor i in range(len(real)):\n",
        "\t\tif real[i] == predicted[i]:\n",
        "\t\t\tcorrect += 1\n",
        "\treturn correct / float(len(real)) * 100.0\n",
        "\n",
        "accuracy(test_y, results)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 ... 8 2 2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78.49000000000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKKFw85AO1vz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1d07f979-8362-4458-a25d-ed1bdc8a5b6d"
      },
      "source": [
        "trainpred = tree.predict(train_X)\n",
        "print(trainpred)\n",
        "\n",
        "accuracy(train_y, trainpred)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 9 6 ... 8 8 7]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80.81333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1CPSadDcGzn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "1f3dad80-ad4a-4d5a-dff8-091b4db254a0"
      },
      "source": [
        "import seaborn as sns\n",
        "ax = sns.countplot(x=\"label\", data=df_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY0r2R_EbRbd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#RandomForest\n",
        "def bootstrap_sample(X,y):\n",
        "    n_sample = X.shape[0]\n",
        "    idxs = np.random.choice(n_sample, size = 1200, replace = True)\n",
        "    return X[idxs], y[idxs]\n",
        "\n",
        "def most_common_label(y):\n",
        "    counter = Counter(y)\n",
        "    most_common = counter.most_common(1)[0][0]\n",
        "    return most_common\n",
        "\n",
        "class RandomForest:\n",
        "    \n",
        "    def __init__(self, n_trees= 250, min_samples_split= 2, max_depth = 10, n_feats = 25):\n",
        "        self.n_trees = n_trees\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        self.n_feats = n_feats\n",
        "        self.trees = []\n",
        "        \n",
        "    \n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        self.trees = []\n",
        "        for _ in range(self.n_trees):\n",
        "            tree = DecisionTree(min_samples_split = 2, max_depth= 10, n_feats= 25)\n",
        "            X_sample, y_sample = bootstrap_sample(X, y)    \n",
        "            tree.fit(X_sample, y_sample)\n",
        "            self.trees.append(tree)\n",
        "        \n",
        "        \n",
        "    \n",
        "    def predict(self, X):\n",
        "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
        "        tree_preds = np.swapaxes(tree_preds, 0, 1)\n",
        "        y_pred = [most_common_label(tree_pred) for tree_pred in tree_preds]\n",
        "        return np.array(y_pred)\n",
        "    "
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ar35XmXba8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Implementation on the dataset\n",
        "RandomForest= RandomForest()\n",
        "Fit100= RandomForest.fit(train_X, train_y)\n",
        "pred100 = RandomForest.predict(test_X)\n",
        "accuracy100 = accuracy(test_y,pred100)\n",
        "print(accuracy100)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP0SFUsY48BH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1970d1fc-da32-4f63-8792-0a95d28b0f6c"
      },
      "source": [
        "RandomForest= RandomForest()\n",
        "Fit150= RandomForest.fit(train_X, train_y)\n",
        "pred150 = RandomForest.predict(test_X)\n",
        "accuracy150 = accuracy(test_y,pred150)\n",
        "print(accuracy150)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "82.89999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FM7Pf9d5qvV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ae719d5-ae06-4880-84bb-e7b2c52d88c4"
      },
      "source": [
        "RandomForest= RandomForest()\n",
        "Fit200= RandomForest.fit(train_X, train_y)\n",
        "pred200 = RandomForest.predict(test_X)\n",
        "accuracy200 = accuracy(test_y,pred200)\n",
        "print(accuracy200)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "83.35000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQO5VBuj50tq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc6d9e07-ca57-458c-a056-c857b5a42c17"
      },
      "source": [
        "RandomForest= RandomForest()\n",
        "Fit250= RandomForest.fit(train_X, train_y)\n",
        "pred250 = RandomForest.predict(test_X)\n",
        "accuracy250 = accuracy(test_y,pred250)\n",
        "print(accuracy250)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "82.86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyZBbcdb5_SF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RandomForest= RandomForest()\n",
        "Fit300= RandomForest.fit(train_X, train_y)\n",
        "pred300 = RandomForest.predict(test_X)\n",
        "accuracy300 = accuracy(test_y,pred300)\n",
        "print(accuracy300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7Mccn76fUxs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "c60add76-26e2-4743-b5f3-a116f7cd0319"
      },
      "source": [
        "n_estimators = range(1,300,50)\n",
        "for n_estimator in n_estimators :\n",
        "  Fits = []\n",
        "  Fit = RandomForest.fit(train_X, train_y, n_trees= n_estimator)\n",
        "  Fits.append(Fit)\n",
        "  predictions = []\n",
        "  pred = RandomForest.predict(test_X)\n",
        "  predictions.append(pred)\n",
        "  print(Fits)\n",
        "  print(predictions)\n",
        "\n",
        "  for pred in predictions:\n",
        "    print(accuracy(test_y, pred))\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-10636237de63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn_estimator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mn_estimators\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mFits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mFit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trees\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mn_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mFits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'n_trees'"
          ]
        }
      ]
    }
  ]
}